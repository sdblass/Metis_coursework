{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50eca3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time, random\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57dfd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_driver_proxy(base_url): # Retrieves soup from website using Selenium\n",
    "#     driver = webdriver.Chrome()\n",
    "    YOUR_API_KEY = 'OavaC96DqSNsO1vM2qStOhzTZoeOakNd'\n",
    "    target_url = urllib.parse.quote(base_url, safe='~')\n",
    "\n",
    "    URL = f\"https://api.webscrapingapi.com/v1/?api_key={YOUR_API_KEY}&url=\" + target_url\n",
    "\n",
    "    driver_proxy.get(URL)\n",
    "    time.sleep(2 + random.uniform(-1,1))\n",
    "\n",
    "    # check if accept cookie button\n",
    "\n",
    "    try: \n",
    "        cookie_button = driver_proxy.find_elements_by_xpath('//button[@class=\"confirm button radius margin-small secondary right\"]')\n",
    "        cookie_button[0].click()\n",
    "        time.sleep(3 + random.uniform(-1,0))\n",
    "#         driver_proxy.get(URL)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    r = driver_proxy.page_source\n",
    "    \n",
    "#     driver.quit()\n",
    "    return bs(r, 'html.parser')  \n",
    "#     return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f3d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_wbw(): # launches headless browser selenium\n",
    "    options = Options()\n",
    "    options.headless = False\n",
    "    return webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d25ef9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_df_redo(path): # takes in file path of df\n",
    "    try: \n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "        if 'overdrive_author' not in list(df.columns):\n",
    "            df['overdrive_author'] = np.nan\n",
    "        sub_df = df[df['Library copies'] == 'info unavailable'] #| (df.overdrive_author.isna())]\n",
    "        indices = list(sub_df.index)\n",
    "#         print(start_index)\n",
    "    except FileNotFoundError:\n",
    "        return 0, 0\n",
    "    \n",
    "    return indices, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "230f7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_webpage_proxy(base_url):\n",
    "    YOUR_API_KEY = 'OavaC96DqSNsO1vM2qStOhzTZoeOakNd'\n",
    "    target_url = urllib.parse.quote(base_url, safe='~')\n",
    "    URL = f\"https://api.webscrapingapi.com/v1/?api_key={YOUR_API_KEY}&url=\" + target_url\n",
    "    driver_proxy.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5914b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hold_categories(path):\n",
    "    \n",
    "    global driver_proxy\n",
    "    global list_of_hold_categories\n",
    "    driver_proxy = initiate_wbw()\n",
    "#     driver_proxy.maximize_window()\n",
    "    \n",
    "    list_of_indices, df = import_df_redo(path)\n",
    "    base_url = 'https://nypl.overdrive.com'\n",
    "    \n",
    "    list_of_hold_categories = []\n",
    "\n",
    "#     position_start_index = list(df.index).index(start_index)\n",
    "#     list_of_indices = list(df.index[position_start_index:])\n",
    "    \n",
    "#     print(list_of_indices)\n",
    "    for index in list_of_indices:\n",
    "        \n",
    "        index = int(index)\n",
    "        if df.loc[index, 'overdrive_url'] != 'title not found':\n",
    "#         print('ding')\n",
    "            \n",
    "#             print (base_url + df.loc[index, 'overdrive_url'])\n",
    "#             break\n",
    "      \n",
    "\n",
    "            if df.loc[index, 'People waiting per copy'] == 'info unavailable':\n",
    "                \n",
    "                            # check for a holds_info button. If there, click it.\n",
    "                load_webpage_proxy(base_url + df.loc[index, 'overdrive_url'])\n",
    "                \n",
    "                try:\n",
    "\n",
    "                    # click hold_time_info button\n",
    "                    buttons = driver_proxy.find_elements_by_xpath('//button[@aria-label=\"Holds ratio explanation.\"]')\n",
    "                    buttons[0].click()\n",
    "#                     WebDriverWait(driver_proxy, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"Holds ratio explanation.\"]')))\n",
    "\n",
    "                    time.sleep(3 + random.uniform(-1,1))\n",
    "\n",
    "                    # grab html and parse into soup\n",
    "                    soup = bs(driver_proxy.page_source, 'html.parser') \n",
    "\n",
    "                    # extract hold_info like wait-time, number of people waiting, etc.\n",
    "                    holds_info_soup = soup.find_all('p', class_='detail')\n",
    "                    holds_info = [info.text.split(':') for info in holds_info_soup]\n",
    "                    print('holds_info')\n",
    "                    print(holds_info)\n",
    "                    # remove extra spaces\n",
    "#                     list_results = []\n",
    "                    for row in holds_info:\n",
    "                        row[:] = [info.strip() for info in row]\n",
    "\n",
    "                    # convert result into sub_df\n",
    "                    holds_info = np.array(holds_info)\n",
    "                    \n",
    "                    list_of_hold_categories += [holds_info[:,0]]\n",
    "                    \n",
    "#                     print(list_of_hold_categories)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    #                 print('apparently there was an error checking for holds_button button. maybe missing col names or no holds button')\n",
    "                    # grab html and parse into soup\n",
    "                    pass\n",
    "        \n",
    "        print(list_of_hold_categories)\n",
    "        time.sleep(10 + random.uniform(-1,1))\n",
    "        \n",
    "#     return pd.DataFrame(list_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14b6d821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "[]\n",
      "holds_info\n",
      "[['Wait time', ' About 3 weeks'], ['Library copies', ' 4'], ['People waiting in total', ' 4'], ['People waiting per copy', ' 1']]\n",
      "[array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23')]\n",
      "list index out of range\n",
      "[array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23')]\n",
      "holds_info\n",
      "[['Wait time', ' About 3 weeks'], ['Library copies', ' 29'], ['People waiting in total', ' 34'], ['People waiting per copy', ' 1']]\n",
      "[array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23'), array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23')]\n",
      "holds_info\n",
      "[['Wait time', ' About 2 weeks'], ['Library copies', ' 4'], ['People waiting in total', ' 3'], ['People waiting per copy', ' < 1']]\n",
      "[array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23'), array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23'), array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23')]\n",
      "list index out of range\n",
      "[array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23'), array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23'), array(['Wait time', 'Library copies', 'People waiting in total',\n",
      "       'People waiting per copy'], dtype='<U23')]\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: window was already closed\n  (Session info: chrome=97.0.4692.71)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/x16nkyxn74s8p16m4l_9dqh00000gn/T/ipykernel_18535/3762834187.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_hold_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Figures/good_reads_df_hold_categories.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/b1/x16nkyxn74s8p16m4l_9dqh00000gn/T/ipykernel_18535/590577040.py\u001b[0m in \u001b[0;36mget_hold_categories\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                             \u001b[0;31m# check for a holds_info button. If there, click it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mload_webpage_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'overdrive_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/b1/x16nkyxn74s8p16m4l_9dqh00000gn/T/ipykernel_18535/1736790494.py\u001b[0m in \u001b[0;36mload_webpage_proxy\u001b[0;34m(base_url)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'~'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://api.webscrapingapi.com/v1/?api_key={YOUR_API_KEY}&url=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdriver_proxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/opt/anaconda3/envs/metis/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: window was already closed\n  (Session info: chrome=97.0.4692.71)\n"
     ]
    }
   ],
   "source": [
    "get_hold_categories('Figures/good_reads_df_hold_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f44a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.webscrapingapi.com/v1\"\n",
    "\n",
    "params = {\n",
    "  \"api_key\":\"OavaC96DqSNsO1vM2qStOhzTZoeOakNd\",\n",
    "  \"url\":\"https://nypl.overdrive.com/media/6069813\",\n",
    "  \"proxy_type\":\"datacenter\",\n",
    "  \"country\":\"us\",\n",
    "  \"session\":\"100\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, params=params)\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1576735",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "085afec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='detail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741587f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
